{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project--->>Activity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It might take some time to run the complete Project depending on processor.\n",
    "#So kindly Run the Program and Then start Reading the Comments\n",
    "#Comments are present for Each line of code so that it can help user to understand the Project in Better Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The idea here is Data is present in text File \n",
    "#Since the data have two seprated Folder Train and Test\n",
    "#And in that we have data present in two different Folder that is Phone(Data collected from Smart phone ) and Watch(Data collected by smart watch)\n",
    "#Each phone and watch has Accel and Gyro\n",
    "#So we collect all Data of train and prepare a Numpy array so that we can Feed it in our Model\n",
    "#Similarly we prepare a Numpy array for test Data to obtain the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries which are used later in this project\n",
    "#First one is Numpy Library\n",
    "#Second one is Pandas library\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have taken some Empty list so that we can store the different things in different list\n",
    "#we are not storing the Ids because we are not using it to train model\n",
    "#we Stores tag Name i.e. Activities tag in taga-tag accel\n",
    "#time list is used to store time taken\n",
    "#x list use to store x sensor data\n",
    "#y list use to store y sensor data\n",
    "#z list use to store z sensor data\n",
    "#In thist cell we fetching the data from phone accel data \n",
    "\n",
    "taga=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "time=[]\n",
    "#Itterating through different file\n",
    "for i in range(1600,1620):\n",
    "#file is opened in read mode.Path of file along with Name is given\n",
    "    file_obj=open('C:/Users/User/Desktop/DataScienceCN/pro/train/phone/accel/data_'+str(i)+'_accel_phone.txt')\n",
    "#readlines is used to read the data in text file line by line\n",
    "    file_data_phone=file_obj.readlines()\n",
    "#Itterating over the Each line\n",
    "    for i in file_data_phone:\n",
    "#Since different data is seprated by comma we are spliting the line on comma to store the different types of data in different list \n",
    "        val=i.split(',')\n",
    "#ignoring the values of id\n",
    "#storing the value of tag,time,x_sensor_data,Y_sensor_data,z_sensor_data in their respected list\n",
    "        taga.append(val[1])\n",
    "        time.append(float(val[2]))\n",
    "        x.append(float(val[3]))\n",
    "        y.append(float(val[4]))\n",
    "#Since /n is also coming therfore using idexing to remove it\n",
    "        z.append(float(val[5][:-2]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1580245, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the list using np.vstack concatenation in done column wise \n",
    "#Transposing it and printing the shape\n",
    "o_array_phone_a=np.vstack((x,y,z,time))\n",
    "o_array_phone_a=o_array_phone_a.T\n",
    "o_array_phone_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have taken some Empty list so that we can store the different things in different list\n",
    "#we are not storing the Ids because we are not using it to train model\n",
    "#we Stores tag Name i.e. Activities tag in tagg-tag gyro\n",
    "#time list is used to store time taken\n",
    "#x list use to store x sensor data\n",
    "#y list use to store y sensor data\n",
    "#z list use to store z sensor data\n",
    "#In thist cell we fetching the data from phone gyro data\n",
    "tagg=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "time=[]\n",
    "#Itterating through different file\n",
    "for i in range(1600,1620):\n",
    "#file is opened in read mode.Path of file along with Name is given\n",
    "    file_obj=open('C:/Users/User/Desktop/DataScienceCN/pro/train/phone/gyro/data_'+str(i)+'_gyro_phone.txt')\n",
    "#readlines is used to read the data in text file line by line\n",
    "    file_data_phone=file_obj.readlines()\n",
    "#Itterating over the Each line\n",
    "    for i in file_data_phone:\n",
    "#Since different data is seprated by comma we are spliting the line on comma to store the different types of data in different list \n",
    "        val=i.split(',')\n",
    "#ignoring the values of id\n",
    "#storing the value of tag,time,x_sensor_data,Y_sensor_data,z_sensor_data in their respected list\n",
    "        tagg.append(val[1])\n",
    "        time.append(float(val[2]))\n",
    "        x.append(float(val[3]))\n",
    "        y.append(float(val[4]))\n",
    "#Since /n is also coming therfore using idexing to remove it\n",
    "        z.append(float(val[5][:-2]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1387312, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the list using np.vstack concatenation in done column wise \n",
    "#Transposing it and printing the shape\n",
    "o_array_phone_g=np.vstack((x,y,z,time))\n",
    "o_array_phone_g=o_array_phone_g.T\n",
    "o_array_phone_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2967557, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we Concatenating all the Data(Making a single numpy Array) we have found using the phone in train Folder(Data collected from smart Phone)\n",
    "#Printing the shape\n",
    "total_o_array_phone=np.concatenate((o_array_phone_a,o_array_phone_g))\n",
    "total_o_array_phone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating all tags(Making a single Numpy Array) for tags we have found using phone(Data collected using smart phone)\n",
    "total_label_array_phone=np.concatenate((taga,tagg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the similar step to collect data from watch Folder of train(Data collected from smart watch)\n",
    "#we have taken some Empty list so that we can store the different things in different list\n",
    "#we are not storing the Ids because we are not using it to train model\n",
    "#we Stores tag Name i.e. Activities tag in tagg-tag gyro\n",
    "#time list is used to store time taken\n",
    "#x list use to store x sensor data\n",
    "#y list use to store y sensor data\n",
    "#z list use to store z sensor data\n",
    "#In thist cell we fetching the data from phone accel data\n",
    "taga=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "time=[]\n",
    "#Itterating through different file\n",
    "for i in range(1600,1620):\n",
    "#file is opened in read mode.Path of file along with Name is given\n",
    "    file_obj=open('C:/Users/User/Desktop/DataScienceCN/pro/train/watch/accel/data_'+str(i)+'_accel_watch.txt')\n",
    "#readlines is used to read the data in text file line by line\n",
    "    file_data_phone=file_obj.readlines()\n",
    "#Itterating over the Each line\n",
    "    for i in file_data_phone:\n",
    "#Since different data is seprated by comma we are spliting the line on comma to store the different types of data in different list \n",
    "        val=i.split(',')\n",
    "#ignoring the values of id\n",
    "#storing the value of tag,time,x_sensor_data,Y_sensor_data,z_sensor_data in their respected list\n",
    "        taga.append(val[1])\n",
    "        time.append(float(val[2]))\n",
    "        x.append(float(val[3]))\n",
    "        y.append(float(val[4]))\n",
    "#Since /n is also coming therfore using idexing to remove it\n",
    "        z.append(float(val[5][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1304015, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the lists using np.vstack concatenation in done column wise \n",
    "#Transposing it and printing the shape\n",
    "o_array_watch_a=np.vstack((x,y,z,time))\n",
    "o_array_watch_a=o_array_watch_a.T\n",
    "o_array_watch_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have taken some Empty list so that we can store the different things in different list\n",
    "#we are not storing the Ids because we are not using it to train model\n",
    "#we Stores tag Name i.e. Activities tag in tagg-tag gyro\n",
    "#time list is used to store time taken\n",
    "#x list use to store x sensor data\n",
    "#y list use to store y sensor data\n",
    "#z list use to store z sensor data\n",
    "#In thist cell we fetching the data from phone gyro data\n",
    "tagg=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "time=[]\n",
    "#Itterating through different file\n",
    "for i in range(1600,1620):\n",
    "#file is opened in read mode.Path of file along with Name is given\n",
    "    file_obj=open('C:/Users/User/Desktop/DataScienceCN/pro/train/watch/gyro/data_'+str(i)+'_gyro_watch.txt')\n",
    "#readlines is used to read the data in text file line by line\n",
    "    file_data_phone=file_obj.readlines()\n",
    "#Itterating over the Each line\n",
    "    for i in file_data_phone:\n",
    "#Since different data is seprated by comma we are spliting the line on comma to store the different types of data in different list \n",
    "        val=i.split(',')\n",
    "#ignoring the values of id\n",
    "#storing the value of tag,time,x_sensor_data,Y_sensor_data,z_sensor_data in their respected list    \n",
    "        #ids.append(float(val[0]))\n",
    "        tagg.append(val[1])\n",
    "        time.append(float(val[2]))\n",
    "        x.append(float(val[3]))\n",
    "        y.append(float(val[4]))\n",
    "#Since /n is also coming therfore using idexing to remove it\n",
    "        z.append(float(val[5][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1303438, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the lists using np.vstack concatenation in done column wise \n",
    "#Transposing it and printing the shape\n",
    "o_array_watch_g=np.vstack((x,y,z,time))\n",
    "o_array_watch_g=o_array_watch_g.T\n",
    "o_array_watch_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2607453, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we Concatenating all the Data(Making a single numpy Array) we have found using the watch in train Folder(Data collected from smart Watch)\n",
    "#Printing the shape\n",
    "total_o_array_watch=np.concatenate((o_array_watch_a,o_array_watch_g))\n",
    "total_o_array_watch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating all tags(Making a single Numpy Array) for tags we have found using watch(Data collected using smart watch)\n",
    "total_label_array_watch=np.concatenate((taga,tagg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are concatenating all the data that we found from smart phone and smart watch for subject 1600 to 1619\n",
    "#this complete Numpy array for features and targets is served as training Data for our model\n",
    "data_array=np.concatenate((total_o_array_phone,total_o_array_watch))\n",
    "target_array=np.concatenate((total_label_array_phone,total_label_array_watch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the data is collected from sensor and time values are not is Range of sensor values\n",
    "#Therfore we have used the scaler \n",
    "#the scaler here we used is standard scaler which makes means 0 and variance to be unity\n",
    "#we have imported the scaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Creating the scaler object\n",
    "scaler=StandardScaler()\n",
    "#fitting and transforming the training Data.storing the training data again in data_array\n",
    "data_array=scaler.fit_transform(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since the Training data is ready in Numpy array format Now we collect or fetch the Test data from text file\n",
    "#Now we repeat the same above procedures again to Fetch the testing data and make it in specified Numpy array format.\n",
    "#we have taken some Empty list so that we can store the different things in different list\n",
    "#we are not storing the Ids because we are not using it to test model\n",
    "#we Stores tag Name i.e. Activities tag in taga-tag accel\n",
    "#time list is used to store time taken\n",
    "#x list use to store x sensor data\n",
    "#y list use to store y sensor data\n",
    "#z list use to store z sensor data\n",
    "#In thist cell we fetching the data from phone accel data \n",
    "taga=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "time=[]\n",
    "#Itterating through different file\n",
    "for i in range(1620,1634):\n",
    "#file is opened in read mode.Path of file along with Name is given\n",
    "    file_obj=open('C:/Users/User/Desktop/DataScienceCN/pro/test/phone/accel/data_'+str(i)+'_accel_phone.txt')\n",
    "#readlines is used to read the data in text file line by line\n",
    "    file_data_phone=file_obj.readlines()\n",
    "#Itterating over the Each line\n",
    "    for i in file_data_phone:\n",
    "#Since different data is seprated by comma we are spliting the line on comma to store the different types of data in different list \n",
    "        val=i.split(',')\n",
    "#ignoring the values of id\n",
    "#storing the value of tag,time,x_sensor_data,Y_sensor_data,z_sensor_data in their respected list    \n",
    "        taga.append(val[1])\n",
    "        time.append(float(val[2]))\n",
    "        x.append(float(val[3]))\n",
    "        y.append(float(val[4]))\n",
    "#Since /n is also coming therfore using idexing to remove it\n",
    "        z.append(float(val[5][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284034, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the lists using np.vstack concatenation in done column wise \n",
    "#Transposing it and printing the shape\n",
    "o_array_phone_a_test=np.vstack((x,y,z,time))\n",
    "o_array_phone_a_test=o_array_phone_a_test.T\n",
    "o_array_phone_a_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have taken some Empty list so that we can store the different things in different list\n",
    "#we are not storing the Ids because we are not using it to test model\n",
    "#we Stores tag Name i.e. Activities tag in tagg-tag gyro\n",
    "#time list is used to store time taken\n",
    "#x list use to store x sensor data\n",
    "#y list use to store y sensor data\n",
    "#z list use to store z sensor data\n",
    "#In thist cell we fetching the data from phone gyro data \n",
    "tagg=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "time=[]\n",
    "#Itterating through different file\n",
    "for i in range(1620,1634):\n",
    "#file is opened in read mode.Path of file along with Name is given\n",
    "    file_obj=open('C:/Users/User/Desktop/DataScienceCN/pro/test/phone/gyro/data_'+str(i)+'_gyro_phone.txt')\n",
    "#readlines is used to read the data in text file line by line\n",
    "    file_data_phone=file_obj.readlines()\n",
    "#Itterating over the Each line\n",
    "    for i in file_data_phone:\n",
    "#Since different data is seprated by comma we are spliting the line on comma to store the different types of data in different list \n",
    "        val=i.split(',')\n",
    "#ignoring the values of id\n",
    "#storing the value of tag,time,x_sensor_data,Y_sensor_data,z_sensor_data in their respected list    \n",
    "        tagg.append(val[1])\n",
    "        time.append(float(val[2]))\n",
    "        x.append(float(val[3]))\n",
    "        y.append(float(val[4]))\n",
    "#Since /n is also coming therfore using idexing to remove it\n",
    "        z.append(float(val[5][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986266, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the lists using np.vstack concatenation in done column wise \n",
    "#Transposing it and printing the shape\n",
    "o_array_phone_g_test=np.vstack((x,y,z,time))\n",
    "o_array_phone_g_test=o_array_phone_g_test.T\n",
    "o_array_phone_g_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2270300, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we Concatenating all the Data(Making a single numpy Array) we have found using the phone in test Folder(Data collected from smart phone)\n",
    "#Printing the shape\n",
    "total_o_array_phone_test=np.concatenate((o_array_phone_a_test,o_array_phone_g_test))\n",
    "total_o_array_phone_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2270300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating all tags(Making a single Numpy Array) for tags we have found using phone(Data collected using smart phone)\n",
    "#printing the shape\n",
    "total_label_array_phone_test=np.concatenate((taga,tagg))\n",
    "total_label_array_phone_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have taken some Empty list so that we can store the different things in different list\n",
    "#we are not storing the Ids because we are not using it to test model\n",
    "#we Stores tag Name i.e. Activities tag in taga-tag accel\n",
    "#time list is used to store time taken\n",
    "#x list use to store x sensor data\n",
    "#y list use to store y sensor data\n",
    "#z list use to store z sensor data\n",
    "#In thist cell we fetching the data from watch accel data \n",
    "taga=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "time=[]\n",
    "#Itterating through different file\n",
    "for i in range(1620,1634):\n",
    "#file is opened in read mode.Path of file along with Name is given\n",
    "    file_obj=open('C:/Users/User/Desktop/DataScienceCN/pro/test/watch/accel/data_'+str(i)+'_accel_watch.txt')\n",
    "#readlines is used to read the data in text file line by line\n",
    "    file_data_phone=file_obj.readlines()\n",
    "#Itterating over the Each line    \n",
    "    for i in file_data_phone:\n",
    "#Since different data is seprated by comma we are spliting the line on comma to store the different types of data in different list\n",
    "        val=i.split(',')\n",
    "#ignoring the values of id\n",
    "#storing the value of tag,time,x_sensor_data,Y_sensor_data,z_sensor_data in their respected list\n",
    "        taga.append(val[1])\n",
    "        time.append(float(val[2]))\n",
    "        x.append(float(val[3]))\n",
    "        y.append(float(val[4]))\n",
    "#Since /n is also coming therfore using idexing to remove it\n",
    "        z.append(float(val[5][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998280, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the lists using np.vstack concatenation in done column wise \n",
    "#Transposing it and printing the shape\n",
    "o_array_watch_a_test=np.vstack((x,y,z,time))\n",
    "o_array_watch_a_test=o_array_watch_a_test.T\n",
    "o_array_watch_a_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have taken some Empty list so that we can store the different things in different list\n",
    "#we are not storing the Ids because we are not using it to test model\n",
    "#we Stores tag Name i.e. Activities tag in taga-tag accel\n",
    "#time list is used to store time taken\n",
    "#x list use to store x sensor data\n",
    "#y list use to store y sensor data\n",
    "#z list use to store z sensor data\n",
    "#In thist cell we fetching the data from watch gyro data \n",
    "tagg=[]\n",
    "x=[]\n",
    "y=[]\n",
    "z=[]\n",
    "time=[]\n",
    "#Itterating through different file\n",
    "for i in range(1620,1634):\n",
    "#file is opened in read mode.Path of file along with Name is given\n",
    "    file_obj=open('C:/Users/User/Desktop/DataScienceCN/pro/test/watch/gyro/data_'+str(i)+'_gyro_watch.txt')\n",
    "#readlines is used to read the data in text file line by line\n",
    "    file_data_phone=file_obj.readlines()\n",
    "#Itterating over the Each line\n",
    "    for i in file_data_phone:\n",
    "#Since different data is seprated by comma we are spliting the line on comma to store the different types of data in different list\n",
    "        val=i.split(',')\n",
    "#ignoring the values of id\n",
    "#storing the value of tag,time,x_sensor_data,Y_sensor_data,z_sensor_data in their respected list\n",
    "        tagg.append(val[1])\n",
    "        time.append(float(val[2]))\n",
    "        x.append(float(val[3]))\n",
    "        y.append(float(val[4]))\n",
    "#Since /n is also coming therfore using idexing to remove it\n",
    "        z.append(float(val[5][:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997751, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating the lists using np.vstack concatenation in done column wise \n",
    "#Transposing it and printing the shape\n",
    "o_array_watch_g_test=np.vstack((x,y,z,time))\n",
    "o_array_watch_g_test=o_array_watch_g_test.T\n",
    "o_array_watch_g_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996031, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we Concatenating all the Data(Making a single numpy Array) we have found using the watch in test Folder(Data collected from smart watch)\n",
    "#Printing the shape\n",
    "total_o_array_watch_test=np.concatenate((o_array_watch_a_test,o_array_watch_g_test))\n",
    "total_o_array_watch_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996031,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating all tags(Making a single Numpy Array) for tags we have found using watch(Data collected using smart watch)\n",
    "#printing the shape\n",
    "total_label_array_watch_test=np.concatenate((taga,tagg))\n",
    "total_label_array_watch_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are concatenating all the data that we found from smart phone and smart watch for subject 1620 to 1633\n",
    "#this complete Numpy array for features and targets is served as testing Data for our model\n",
    "data_array_test=np.concatenate((total_o_array_phone_test,total_o_array_watch_test))\n",
    "target_array_test=np.concatenate((total_label_array_phone_test,total_label_array_watch_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are scaling the test data \n",
    "#using the same scaler which we have used to fit and transform the training data\n",
    "#this is done so that mean becomes 0 and Variance becomes 1.so that One feature cannot dominate other feature\n",
    "data_array_test=scaler.transform(data_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4266331, 4), (4266331,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the shapesfor clarification\n",
    "data_array_test.shape,target_array_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Random Forest classifier for prediction \n",
    "#Also as an alternate model we used some deep learning network\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=6, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(data_array,target_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=clf.predict(data_array_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.26      0.19      0.22    238685\n",
      "           B       0.28      0.22      0.25    243794\n",
      "           C       0.10      0.39      0.15    228180\n",
      "           D       0.13      0.44      0.20    241924\n",
      "           E       0.20      0.18      0.19    254010\n",
      "           F       0.20      0.11      0.14    233184\n",
      "           G       0.11      0.14      0.12    244279\n",
      "           H       0.10      0.12      0.11    228832\n",
      "           I       0.18      0.02      0.04    234942\n",
      "           J       0.10      0.01      0.01    223312\n",
      "           K       0.09      0.02      0.03    248869\n",
      "           L       0.02      0.00      0.00    225801\n",
      "           M       0.06      0.03      0.04    230931\n",
      "           O       0.11      0.05      0.07    231527\n",
      "           P       0.11      0.19      0.14    225440\n",
      "           Q       0.15      0.17      0.16    247684\n",
      "           R       0.07      0.01      0.02    242200\n",
      "           S       0.08      0.03      0.04    242737\n",
      "\n",
      "    accuracy                           0.13   4266331\n",
      "   macro avg       0.13      0.13      0.11   4266331\n",
      "weighted avg       0.13      0.13      0.11   4266331\n",
      "\n",
      "[[ 44674  19402  93713   2214   7324   1458  10603   6543    429    674\n",
      "    1040    181   8677   2283  22279  10389    914   5888]\n",
      " [ 17257  53983  77636   5360   2252   2544  11890   8259    460    705\n",
      "    1393    271  13302   2664  27992  10654   2928   4244]\n",
      " [ 25173  15810  90031   3447   5758   1796  12690  12656    361    814\n",
      "    1302    670  13089   3640  26185   7417   1234   6107]\n",
      " [  1232   9500  34775 107340   8700  12547  22341   4773   1876   1950\n",
      "    1563   4621    979   5995  13836   5064   2096   2736]\n",
      " [  3457   4029  31905  76789  45064   4598   9467  20604    175    683\n",
      "    1721    239   9716   1290  25420  15932    213   2708]\n",
      " [   431    145  27125  76980  12208  24637  18148   9046   2005   1607\n",
      "    8241    366    471  15577   8478  24173    254   3292]\n",
      " [  4552  11272  41719  48003   8094   3274  34357  37341   1688    407\n",
      "    2264   3463  14047   1139  14753   6118   4987   6801]\n",
      " [   996   8760  37358  63838  12515   1253  17673  28428   3288    612\n",
      "    2844   5322   1432   4643  14576  19794   1044   4456]\n",
      " [  1955   1021  22482  74739  13069  19399  28721  10830   5089    901\n",
      "    2927   7477   2221    960  19438  15789   1951   5973]\n",
      " [   686   1971  32553  66108   9181   4748  14872  28668    704   1640\n",
      "    4650    277   1323   6474  17438  19583   7329   5107]\n",
      " [  1862   5863  33237  88483  14129   7428  27115  23172   3488    288\n",
      "    4717   1330   2833    294  14059  15189   3172   2210]\n",
      " [  2241    397  26342  80652  14834   6966  30081  11502   4576    895\n",
      "    2786    504   1215   3735  11416  23571   1677   2411]\n",
      " [ 27474  13069  91410   3310  13364   2216  12632  14710    187    561\n",
      "    1465   1438   6194   3792  22799   9824    867   5619]\n",
      " [ 12566  12271  70068   9959  12733   4027  15452  13888    593    645\n",
      "    1971    975   5709  10940  32876  15866   3557   7431]\n",
      " [ 13540  12124  76453  11204  11572   4503  14780   6390    335    416\n",
      "    1229    548   5090   5530  42452  11946   2529   4799]\n",
      " [   430   2684  46218  69271  14931  10374   3799   4197    754    445\n",
      "   10309    216    584  16539  16540  41219   6334   2840]\n",
      " [  4474  14083  48695  49817   7391   6312  19731  20516   1558    437\n",
      "    1956    232   7853   9936  33593   9212   3211   3193]\n",
      " [  6920   7450  65934  20437  16281   5521  19161  30917   1480   2458\n",
      "    2062    620   9736   2716  31472  10474   2571   6527]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(target_array_test,Y_pred))\n",
    "print(confusion_matrix(target_array_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Keras Model for our Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#importing Sequential Model from keras.models\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the Sequential model object \n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have planned to have 3 Dense layers in my model\n",
    "#If you want you may have more layers but as you increase layers the model become more complex and more time is required\n",
    "#In training and prediction because You have to train More number of weight and biases\n",
    "#Here i have imported Dense layer from keras.layers\n",
    "from keras.layers import Dense\n",
    "#In first layer we have 32 units \n",
    "#Having activation function Relu-->y=x for x>=0\n",
    "#You have to give input dimension for the first layer it is nothing but Number of features you have in your data\n",
    "#By using model.add we have added that layer in our model\n",
    "model.add(Dense(units=256,activation='relu',input_dim=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second layer i have added has 16 units \n",
    "#The activation function here also i have used is Relu \n",
    "model.add(Dense(units=256,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The third layer in our model serve as a output layer \n",
    "#Since there are 18 classes present in target the Number of units taken here is 18\n",
    "#Activation function used is Softmax-->probability distribution sum to 1\n",
    "model.add(Dense(units=18,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have used the Adam optimizer\n",
    "#The Error function we have used is binary_crossentropy\n",
    "#And accuracy metrics is used to tell how good or bad your prediction is\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have used OneHot encoder to change the target value in form of one hot encoding\n",
    "#Since it is a multi class classification\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we reshape the target labels of train data in a numpy 2D array\n",
    "target_array_enc=target_array.reshape(-1,1)\n",
    "#I have made an object of OneHot Encoder\n",
    "enc=OneHotEncoder()\n",
    "#Then fit the data to Encoder and tanform the data the transformed data is Saved in Y_train\n",
    "Y_train=enc.fit_transform(target_array_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now as similar to train data we reshape the test data\n",
    "target_array_test_enc=target_array_test.reshape(-1,1)\n",
    "#then by the help of same enc object we have transformed the test data\n",
    "Y_test=enc.transform(target_array_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5575010, 4)\n",
      "(5575010, 18)\n"
     ]
    }
   ],
   "source": [
    "#Just to verify we are printing the shape of train data\n",
    "print(data_array.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4266331, 4)\n",
      "(4266331, 18)\n"
     ]
    }
   ],
   "source": [
    "#Similarly Just to verify we are printing the shape of test data\n",
    "print(data_array_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5575010 samples, validate on 4266331 samples\n",
      "Epoch 1/20\n",
      "5575010/5575010 [==============================] - 145s 26us/step - loss: 2.9025 - accuracy: 0.0676 - val_loss: 2.8901 - val_accuracy: 0.0605\n",
      "Epoch 2/20\n",
      "5575010/5575010 [==============================] - 146s 26us/step - loss: 2.8863 - accuracy: 0.0741 - val_loss: 2.8882 - val_accuracy: 0.0662\n",
      "Epoch 3/20\n",
      "5575010/5575010 [==============================] - 145s 26us/step - loss: 2.8835 - accuracy: 0.0762 - val_loss: 2.8864 - val_accuracy: 0.0684\n",
      "Epoch 4/20\n",
      "5575010/5575010 [==============================] - 145s 26us/step - loss: 2.8807 - accuracy: 0.0779 - val_loss: 2.8847 - val_accuracy: 0.0696\n",
      "Epoch 5/20\n",
      "5575010/5575010 [==============================] - 138s 25us/step - loss: 2.8778 - accuracy: 0.0789 - val_loss: 2.8829 - val_accuracy: 0.0700\n",
      "Epoch 6/20\n",
      "5575010/5575010 [==============================] - 136s 24us/step - loss: 2.8748 - accuracy: 0.0803 - val_loss: 2.8810 - val_accuracy: 0.0742\n",
      "Epoch 7/20\n",
      "5575010/5575010 [==============================] - 147s 26us/step - loss: 2.8718 - accuracy: 0.0820 - val_loss: 2.8793 - val_accuracy: 0.0739\n",
      "Epoch 8/20\n",
      "5575010/5575010 [==============================] - 146s 26us/step - loss: 2.8686 - accuracy: 0.0834 - val_loss: 2.8774 - val_accuracy: 0.0746\n",
      "Epoch 9/20\n",
      "5575010/5575010 [==============================] - 155s 28us/step - loss: 2.8653 - accuracy: 0.0851 - val_loss: 2.8755 - val_accuracy: 0.0745\n",
      "Epoch 10/20\n",
      "5575010/5575010 [==============================] - 151s 27us/step - loss: 2.8618 - accuracy: 0.0860 - val_loss: 2.8736 - val_accuracy: 0.0756\n",
      "Epoch 11/20\n",
      "5575010/5575010 [==============================] - 150s 27us/step - loss: 2.8582 - accuracy: 0.0870 - val_loss: 2.8716 - val_accuracy: 0.0761\n",
      "Epoch 12/20\n",
      "5575010/5575010 [==============================] - 149s 27us/step - loss: 2.8543 - accuracy: 0.0889 - val_loss: 2.8696 - val_accuracy: 0.0792\n",
      "Epoch 13/20\n",
      "5575010/5575010 [==============================] - 150s 27us/step - loss: 2.8503 - accuracy: 0.0910 - val_loss: 2.8676 - val_accuracy: 0.0786\n",
      "Epoch 14/20\n",
      "5575010/5575010 [==============================] - 146s 26us/step - loss: 2.8462 - accuracy: 0.0924 - val_loss: 2.8656 - val_accuracy: 0.0815\n",
      "Epoch 15/20\n",
      "5575010/5575010 [==============================] - 143s 26us/step - loss: 2.8419 - accuracy: 0.0939 - val_loss: 2.8639 - val_accuracy: 0.0798\n",
      "Epoch 16/20\n",
      "5575010/5575010 [==============================] - 138s 25us/step - loss: 2.8375 - accuracy: 0.0960 - val_loss: 2.8621 - val_accuracy: 0.0808\n",
      "Epoch 17/20\n",
      "5575010/5575010 [==============================] - 138s 25us/step - loss: 2.8330 - accuracy: 0.0962 - val_loss: 2.8604 - val_accuracy: 0.0868\n",
      "Epoch 18/20\n",
      "5575010/5575010 [==============================] - 138s 25us/step - loss: 2.8285 - accuracy: 0.0962 - val_loss: 2.8590 - val_accuracy: 0.0848\n",
      "Epoch 19/20\n",
      "5575010/5575010 [==============================] - 138s 25us/step - loss: 2.8240 - accuracy: 0.0957 - val_loss: 2.8576 - val_accuracy: 0.0862\n",
      "Epoch 20/20\n",
      "5575010/5575010 [==============================] - 151s 27us/step - loss: 2.8197 - accuracy: 0.0956 - val_loss: 2.8564 - val_accuracy: 0.0860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2c518786388>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_array,Y_train,epochs=20,batch_size=20000,validation_data=(data_array_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4266331, 18)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(data_array_test)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4266331/4266331 [==============================] - 2522s 591us/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(data_array_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.8564404535591876, 0.08599051833152771]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
